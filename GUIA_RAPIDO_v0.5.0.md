# Guia R√°pido - Orquestra v0.5.0

Guia r√°pido para usar as novas funcionalidades da vers√£o 0.5.0.

## üåä 1. Streaming (Respostas em Tempo Real)

### Instala√ß√£o
N√£o requer depend√™ncias adicionais. Use com OpenAI ou Anthropic.

### Uso B√°sico

```python
from orquestra import ReactAgent

# Criar agente
agent = ReactAgent(
    name="Assistant",
    provider="gpt-4o-mini"  # ou "claude-3-5-sonnet-20241022"
)

# Streaming s√≠ncrono
for chunk in agent.stream("Conte uma hist√≥ria curta"):
    print(chunk, end="", flush=True)

print("\n")  # Nova linha no final
```

### Streaming Ass√≠ncrono

```python
import asyncio

async def main():
    agent = ReactAgent(name="Assistant", provider="gpt-4o-mini")

    async for chunk in agent.astream("Explique IA em 2 frases"):
        print(chunk, end="", flush=True)

    print()

asyncio.run(main())
```

### Com Tools

O streaming funciona normalmente com tools - a execu√ß√£o da tool n√£o √© streamed, mas a resposta final sim:

```python
agent = ReactAgent(name="Assistant", provider="gpt-4o-mini")

@agent.tool()
def get_weather(city: str) -> str:
    """Get weather for a city"""
    return f"Weather in {city}: Sunny, 25¬∞C"

# Stream com tool calling
for chunk in agent.stream("What's the weather in Paris?"):
    print(chunk, end="", flush=True)
```

---

## üîç 2. Vector Database & RAG

### Instala√ß√£o

```bash
uv add orquestra --optional vectordb
```

### Configura√ß√£o B√°sica

```python
from orquestra.embeddings import OpenAIEmbeddings
from orquestra.vectorstores import ChromaVectorStore, Document

# 1. Criar embedding provider
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small"  # Mais r√°pido e barato
    # model="text-embedding-3-large"  # Melhor qualidade
)

# 2. Criar vector store
store = ChromaVectorStore(
    collection_name="meu_conhecimento",
    embedding_provider=embeddings,
    persist_directory="./chroma_db"  # Opcional: persistir dados
)

# 3. Adicionar documentos
docs = [
    Document(
        content="Python √© uma linguagem de programa√ß√£o de alto n√≠vel.",
        metadata={"source": "docs", "language": "pt"}
    ),
    Document(
        content="JavaScript √© usado principalmente para desenvolvimento web.",
        metadata={"source": "docs", "language": "pt"}
    ),
]

ids = store.add(docs)
print(f"Adicionados {len(ids)} documentos")
```

### Busca Sem√¢ntica

```python
# Buscar por similaridade
results = store.search(
    query="linguagens de programa√ß√£o",
    limit=5,
    filter={"language": "pt"}  # Filtro opcional
)

for result in results:
    print(f"Score: {result.score:.2f}")
    print(f"Content: {result.document.content}")
    print(f"Metadata: {result.document.metadata}")
    print()
```

### RAG Completo com Agente

```python
from orquestra import ReactAgent

# Criar agente
agent = ReactAgent(
    name="Knowledge Assistant",
    provider="gpt-4o-mini"
)

# Adicionar tool de busca
@agent.tool()
def search_knowledge(query: str) -> str:
    """Buscar na base de conhecimento"""
    results = store.search(query, limit=3)

    if not results:
        return "Nenhuma informa√ß√£o encontrada."

    context = "\n\n".join([
        f"[Relev√¢ncia {r.score:.0%}] {r.document.content}"
        for r in results
    ])

    return f"Informa√ß√µes relevantes:\n{context}"

# Agente usa conhecimento automaticamente
answer = agent.run("Quais linguagens de programa√ß√£o voc√™ conhece?")
print(answer)
```

### Com KnowledgeMemory

```python
from orquestra import KnowledgeMemory

# Criar mem√≥ria com vector store
memory = KnowledgeMemory(vector_store=store)

# Adicionar conhecimento
memory.add("Orquestra √© um framework de agentes AI")
memory.add("Suporta OpenAI, Anthropic, Gemini e Ollama")

# Buscar semanticamente
results = memory.search("framework IA", limit=3)
for result in results:
    print(result.content)
```

---

## ü§ù 3. Orquestra√ß√£o de Agentes

### Workflow Sequencial

```python
from orquestra import ReactAgent
from orquestra.orchestration import SequentialWorkflow

# Criar agentes especializados
researcher = ReactAgent(
    name="Pesquisador",
    description="Pesquisa informa√ß√µes sobre um t√≥pico",
    provider="gpt-4o-mini"
)

writer = ReactAgent(
    name="Escritor",
    description="Escreve artigos baseados em pesquisa",
    provider="gpt-4o-mini"
)

editor = ReactAgent(
    name="Editor",
    description="Revisa e melhora textos",
    provider="gpt-4o-mini"
)

# Criar workflow
workflow = SequentialWorkflow(name="Produ√ß√£o de Artigo")
workflow.add_agent(researcher)  # Passo 1: Pesquisar
workflow.add_agent(writer)      # Passo 2: Escrever
workflow.add_agent(editor)      # Passo 3: Editar

# Executar - cada agente recebe o output do anterior
result = workflow.run(
    "Escreva um artigo sobre computa√ß√£o qu√¢ntica",
    temperature=0.7
)

print(result)
```

### Workflow Customizado

```python
from orquestra.orchestration import Workflow

# Criar workflow customizado
workflow = Workflow(name="Custom")

# Adicionar steps customizados
workflow.add_step(
    name="research",
    func=researcher.run,
    pass_previous=True  # Recebe input do step anterior
)

workflow.add_step(
    name="custom_processing",
    func=lambda text: text.upper(),  # Fun√ß√£o customizada
    pass_previous=True
)

workflow.add_step(
    name="finalize",
    func=editor.run,
    pass_previous=True
)

# Executar
result = workflow.run("Initial input")
```

---

## üéØ Combinando Tudo: RAG + Streaming + Orchestration

```python
from orquestra import ReactAgent
from orquestra.embeddings import OpenAIEmbeddings
from orquestra.vectorstores import ChromaVectorStore, Document
from orquestra.orchestration import SequentialWorkflow

# 1. Setup vector store
embeddings = OpenAIEmbeddings()
store = ChromaVectorStore(
    collection_name="knowledge",
    embedding_provider=embeddings
)

# Adicionar conhecimento
store.add([
    Document(content="Informa√ß√£o t√©cnica sobre IA..."),
    Document(content="Dados sobre machine learning..."),
])

# 2. Criar agentes com RAG
research_agent = ReactAgent(name="Researcher", provider="gpt-4o-mini")

@research_agent.tool()
def search_docs(query: str) -> str:
    """Buscar documenta√ß√£o"""
    results = store.search(query, limit=3)
    return "\n".join([r.document.content for r in results])

writer_agent = ReactAgent(name="Writer", provider="gpt-4o-mini")

# 3. Criar workflow
workflow = SequentialWorkflow()
workflow.add_agent(research_agent)
workflow.add_agent(writer_agent)

# 4. Executar com streaming
print("Gerando resposta...\n")
for chunk in writer_agent.stream(
    workflow.run("Explique IA de forma simples")
):
    print(chunk, end="", flush=True)

print("\n\nConclu√≠do!")
```

---

## üìù Dicas e Best Practices

### Streaming
- ‚úÖ Use `flush=True` no print para ver chunks em tempo real
- ‚úÖ Combine com frameworks web (FastAPI, Flask) para UIs responsivas
- ‚ö†Ô∏è Tool execution n√£o √© streamed (apenas a resposta final)

### Vector Databases
- ‚úÖ Use `text-embedding-3-small` para economia
- ‚úÖ Use `persist_directory` para n√£o perder dados
- ‚úÖ Adicione metadata para filtros mais precisos
- ‚ö†Ô∏è ChromaDB requer instala√ß√£o separada: `uv add chromadb`

### Orquestra√ß√£o
- ‚úÖ Use agentes especializados (researcher, writer, editor)
- ‚úÖ Configure temperature diferente para cada agente
- ‚úÖ Teste cada agente individualmente antes do workflow
- ‚ö†Ô∏è Workflows podem consumir muitos tokens

---

## üîß Troubleshooting

### Streaming n√£o funciona
```python
# Verificar se provider suporta streaming
if agent.provider.supports_streaming():
    print("Streaming suportado!")
else:
    print("Provider n√£o suporta streaming")
```

### Vector store n√£o encontra resultados
```python
# Verificar se h√° documentos
count = store.count()
print(f"Documentos no store: {count}")

# Tentar sem filtros
results = store.search(query, limit=10)  # Sem filter=
```

### ChromaDB n√£o instalado
```bash
uv add chromadb
# ou
pip install chromadb
```

---

## üìö Recursos Adicionais

- **Exemplos completos**: `/examples/`
  - `streaming_example.py`
  - `vector_rag_example.py`

- **Documenta√ß√£o**: `README.md`
- **Changelog**: `CHANGELOG.md`
- **Implementa√ß√£o**: `IMPLEMENTACAO_v0.5.0.md`

---

## ‚ùì FAQ

**P: Posso usar streaming sem tools?**
R: Sim! Funciona perfeitamente sem tools.

**P: ChromaDB funciona em produ√ß√£o?**
R: Sim! Use `persist_directory` para dados persistentes.

**P: Preciso de GPU para embeddings?**
R: N√£o com OpenAI embeddings (API). Sim com embeddings locais (futura feature).

**P: Workflows s√£o ass√≠ncronos?**
R: SequentialWorkflow √© s√≠ncrono. ParallelWorkflow (futuro) ser√° async.

**P: Posso combinar streaming + RAG?**
R: Sim! Veja exemplo combinado acima.

---

**Vers√£o**: 0.5.0
**Data**: 16/10/2025
**Autor**: Marcos Oliveira
